import cv2
import numpy as np
import base64
from inference_sdk import InferenceHTTPClient
from PIL import Image, ImageDraw, ImageFont
import io

# Initialize the inference client
CLIENT = InferenceHTTPClient(
    api_url="https://detect.roboflow.com",
    api_key="EQrKZhgL8SxzifXnmxn9"
)

# Path to the video file
video_path = r"C:\Users\hanso\Desktop\20240320_102424.mp4"

# Initialize the video capture object
cap = cv2.VideoCapture(video_path)

# Check if the video is opened successfully
if not cap.isOpened():
    print("Error: Failed to open the video file.")
    exit()

# Define the output video parameters
output_width = 854
output_height = 480
output_fps = 30
output_filename = 'output_video.mp4'

# Create a VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
video_writer = cv2.VideoWriter(output_filename, fourcc, output_fps, (output_width, output_height))

# Process each frame in the video
frame_index = 0
while True:
    # Seek to the desired frame index
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)

    # Read a frame from the video
    ret, frame = cap.read()

    # Check if the frame is read successfully
    if not ret:
        break

    # Convert the frame to base64
    _, buffer = cv2.imencode('.jpg', frame)
    jpeg_as_bytes = buffer.tobytes()

    # Perform inference using the base64 image data
    result = CLIENT.infer(base64.b64encode(jpeg_as_bytes).decode('utf-8'), model_id="golfie/5")

    # Convert the frame to PIL Image
    pil_image = Image.open(io.BytesIO(jpeg_as_bytes))

    # Draw coordinates of detected balls on the image
    draw = ImageDraw.Draw(pil_image)
    font = ImageFont.truetype("arial.ttf", 16)
    for prediction in result['predictions']:
        x, y = int(prediction['x']), int(prediction['y'])  # Convert coordinates to integers
        draw.text((x, y), f"({x}, {y})", fill=(255, 0, 0), font=font)

    # Convert PIL Image back to OpenCV format for writing to the video
    frame_with_text = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

    # Write the frame to the output video
    video_writer.write(frame_with_text)

    # Increment frame index
    frame_index += 180  # Adjust as needed

# Release the video capture object and VideoWriter
cap.release()
video_writer.release()

''''''